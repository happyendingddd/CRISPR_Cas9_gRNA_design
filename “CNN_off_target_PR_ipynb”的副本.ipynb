{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“CNN_off_target_PR.ipynb”的副本",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLAZaGl20U4NIBDmZH0g1i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/happyendingddd/CRISPR_Cas9_gRNA_design/blob/main/%E2%80%9CCNN_off_target_PR_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPDIloPHJLDm"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToPvuOW_4tiq"
      },
      "source": [
        "after=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAsslLtrRhcS"
      },
      "source": [
        "# 数据导入1\n",
        "file_path='/content/merge_ot_sgRNA_293r_binary.csv'\n",
        "data_read=pd.read_csv(file_path,sep=',')\n",
        "otSeq=np.array(data_read['OT'])\n",
        "guideSeq=np.array(data_read['Target sgRNA'])\n",
        "labels=np.array(data_read['Cleavage Frequency'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rT58VHnm-HM",
        "outputId": "cf8ed505-1d7b-423d-da01-c896b1cc7227"
      },
      "source": [
        "data_read['Target sgRNA'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(536,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig37f_0tiZ5t"
      },
      "source": [
        "if after==True:\n",
        "  # after专属代码\n",
        "  # 数据导入2（已经是编码形式）\n",
        "  num_read=guideSeq.shape[0]\n",
        "  seqdata_gP=np.load('/content/generated_ot_sgRNA_code_293r_positive.npy')[0:num_read-1]\n",
        "  seqdata_gN=np.load('/content/generated_ot_sgRNA_code_293r_negetive.npy')[0:num_read-1]\n",
        "  seqdata_g=np.vstack([seqdata_gP,seqdata_gN])\n",
        "  labels_gP=np.zeros(seqdata_gP.shape[0])+1\n",
        "  labels_gN=np.zeros(seqdata_gN.shape[0])\n",
        "  labels_g=np.r_[labels_gP,labels_gN]\n",
        "  labels_all=np.r_[labels,labels_g]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUJpJOe6Xh0T"
      },
      "source": [
        "# 0ne_hot编码\n",
        "ntmap = {'A': (1, 0, 0, 0),\n",
        "         'C': (0, 1, 0, 0),\n",
        "         'G': (0, 0, 1, 0),\n",
        "         'T': (0, 0, 0, 1)\n",
        "         }\n",
        "\n",
        "def get_seqcode(seq):\n",
        "    return list(map(lambda c: ntmap[c], seq))\n",
        "\n",
        "def oneHotcoding(Seq):\n",
        "    n=0\n",
        "    for seq in Seq:\n",
        "        if n==0:\n",
        "            SeqcodeL=[]\n",
        "        seqcode=get_seqcode(seq)\n",
        "        n+=1\n",
        "        SeqcodeL.append(seqcode)\n",
        "        seqcode=[]\n",
        "        SeqcodeA=np.array(SeqcodeL)\n",
        "    return SeqcodeA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4eR5tvcRkhV"
      },
      "source": [
        "# OR算子编码sgRNA-DNA\n",
        "def OR(a,b):\n",
        "    ab=np.zeros([a.shape[0],a.shape[1]])\n",
        "    for i in range(a.shape[0]):\n",
        "        for j in range(a.shape[1]):\n",
        "            if a[i][j] != b[i][j]:\n",
        "                ab[i][j]=a[i][j]+b[i][j]\n",
        "            else:\n",
        "                ab[i][j]=a[i][j]\n",
        "    return ab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQfjTbR6csQA"
      },
      "source": [
        "# 编码\n",
        "guidecode=oneHotcoding(guideSeq)\n",
        "otcode=oneHotcoding(otSeq)\n",
        "guide_ot_code=np.zeros((guidecode.shape[0],guidecode.shape[1],guidecode.shape[2]))\n",
        "for i in range(len(guidecode)):\n",
        "    guide_ot_code[i]=OR(guidecode[i],otcode[i])\n",
        "seqdata=guide_ot_code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBlEUwKweQhE",
        "outputId": "fd8127a5-818f-404d-aeb9-79da694036f6"
      },
      "source": [
        "if after==True:\n",
        "  # after专属代码\n",
        "  seqdata_all=np.vstack([seqdata,seqdata_g])\n",
        "  print(seqdata_all.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1606, 23, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryFWKfMci0H2"
      },
      "source": [
        "if after!=True:\n",
        "  # before专属代码\n",
        "  seqdata_all=seqdata\n",
        "  labels_all=labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WXpj3__lw0I",
        "outputId": "ff3240ea-b8b6-433f-c0a7-3dd2f9bb3a06"
      },
      "source": [
        "seqdata_all.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1606, 23, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGTQMvFwmmEI",
        "outputId": "818c9f0f-8eab-4e67-d88b-3c807d15d11c"
      },
      "source": [
        "labels_all.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1606,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgztcQI0ZES9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_seq,test_seq,train_lab,test_lab=train_test_split(seqdata_all,labels_all,train_size = 0.6,random_state=0,stratify=labels_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "579mL7Rsb-NO"
      },
      "source": [
        "val_seq=test_seq[:int(test_seq.shape[0]*0.25)];val_lab=test_lab[:int(test_seq.shape[0]*0.25)]\n",
        "Ntest_seq=test_seq[int(test_seq.shape[0]*0.25)+1:];Ntest_lab=test_lab[int(test_seq.shape[0]*0.25)+1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AAGqIGzWYym",
        "outputId": "31817698-284f-4266-a0e2-bfa674974570"
      },
      "source": [
        "sum(Ntest_lab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "227.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRdwI4H4J6GM"
      },
      "source": [
        "def CNN_model():\n",
        "  model = tf.keras.Sequential()\n",
        "  \n",
        "  model.add(layers.Conv1D(16, 3, padding='same', activation='relu', input_shape=(23,4)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv1D(64, 3,padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv1D(64, 3,padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(16, activation='relu'))\n",
        "  #model.add(layers.Dense(2))\n",
        "  model.add(layers.Dense(2,activation='sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaSwu0mpR2MR"
      },
      "source": [
        "model=CNN_model()\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WewlvP6SLbc"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z04ozd0wNsfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c93c722f-afb4-44dc-cbec-484a6ecbd3ca"
      },
      "source": [
        "history = model.fit(train_seq, train_lab, epochs=200, batch_size=16,\n",
        "                    validation_data=(val_seq, val_lab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "61/61 [==============================] - 2s 18ms/step - loss: 0.8662 - accuracy: 0.6001 - val_loss: 0.6763 - val_accuracy: 0.4688\n",
            "Epoch 2/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.4057 - accuracy: 0.8156 - val_loss: 0.6542 - val_accuracy: 0.4812\n",
            "Epoch 3/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.3482 - accuracy: 0.8381 - val_loss: 0.5492 - val_accuracy: 0.7750\n",
            "Epoch 4/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.3600 - accuracy: 0.8178 - val_loss: 0.4965 - val_accuracy: 0.7437\n",
            "Epoch 5/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.2864 - accuracy: 0.8534 - val_loss: 0.3560 - val_accuracy: 0.8062\n",
            "Epoch 6/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.3208 - accuracy: 0.8500 - val_loss: 0.2840 - val_accuracy: 0.8562\n",
            "Epoch 7/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.2268 - accuracy: 0.8910 - val_loss: 0.2381 - val_accuracy: 0.8687\n",
            "Epoch 8/200\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.2452 - accuracy: 0.8689 - val_loss: 0.2252 - val_accuracy: 0.8750\n",
            "Epoch 9/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.2341 - accuracy: 0.8735 - val_loss: 0.2239 - val_accuracy: 0.8562\n",
            "Epoch 10/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.2332 - accuracy: 0.8723 - val_loss: 0.2234 - val_accuracy: 0.8750\n",
            "Epoch 11/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.2049 - accuracy: 0.8984 - val_loss: 0.2213 - val_accuracy: 0.8938\n",
            "Epoch 12/200\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.2092 - accuracy: 0.8969 - val_loss: 0.2203 - val_accuracy: 0.8875\n",
            "Epoch 13/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.2113 - accuracy: 0.8952 - val_loss: 0.2192 - val_accuracy: 0.8687\n",
            "Epoch 14/200\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.2213 - accuracy: 0.8812 - val_loss: 0.2248 - val_accuracy: 0.8813\n",
            "Epoch 15/200\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.2107 - accuracy: 0.8892 - val_loss: 0.2187 - val_accuracy: 0.8813\n",
            "Epoch 16/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.2073 - accuracy: 0.8974 - val_loss: 0.2244 - val_accuracy: 0.8813\n",
            "Epoch 17/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.2125 - accuracy: 0.8990 - val_loss: 0.2154 - val_accuracy: 0.8625\n",
            "Epoch 18/200\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.2033 - accuracy: 0.9050 - val_loss: 0.2129 - val_accuracy: 0.8687\n",
            "Epoch 19/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1984 - accuracy: 0.9005 - val_loss: 0.2330 - val_accuracy: 0.8750\n",
            "Epoch 20/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1922 - accuracy: 0.9006 - val_loss: 0.2179 - val_accuracy: 0.8750\n",
            "Epoch 21/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1896 - accuracy: 0.9035 - val_loss: 0.2215 - val_accuracy: 0.8813\n",
            "Epoch 22/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1892 - accuracy: 0.9061 - val_loss: 0.2147 - val_accuracy: 0.8562\n",
            "Epoch 23/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1689 - accuracy: 0.9086 - val_loss: 0.2322 - val_accuracy: 0.8750\n",
            "Epoch 24/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1740 - accuracy: 0.9240 - val_loss: 0.2312 - val_accuracy: 0.8938\n",
            "Epoch 25/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1768 - accuracy: 0.8988 - val_loss: 0.2153 - val_accuracy: 0.8813\n",
            "Epoch 26/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1777 - accuracy: 0.9187 - val_loss: 0.2287 - val_accuracy: 0.8938\n",
            "Epoch 27/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1772 - accuracy: 0.9133 - val_loss: 0.2371 - val_accuracy: 0.8938\n",
            "Epoch 28/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1877 - accuracy: 0.9135 - val_loss: 0.2204 - val_accuracy: 0.9000\n",
            "Epoch 29/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1539 - accuracy: 0.9261 - val_loss: 0.2561 - val_accuracy: 0.8938\n",
            "Epoch 30/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1830 - accuracy: 0.8982 - val_loss: 0.2254 - val_accuracy: 0.8875\n",
            "Epoch 31/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1446 - accuracy: 0.9322 - val_loss: 0.2222 - val_accuracy: 0.9000\n",
            "Epoch 32/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1839 - accuracy: 0.8924 - val_loss: 0.2282 - val_accuracy: 0.8813\n",
            "Epoch 33/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1351 - accuracy: 0.9394 - val_loss: 0.2383 - val_accuracy: 0.8875\n",
            "Epoch 34/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1546 - accuracy: 0.9340 - val_loss: 0.2360 - val_accuracy: 0.8687\n",
            "Epoch 35/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1365 - accuracy: 0.9416 - val_loss: 0.2346 - val_accuracy: 0.8938\n",
            "Epoch 36/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1394 - accuracy: 0.9237 - val_loss: 0.2271 - val_accuracy: 0.9000\n",
            "Epoch 37/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1439 - accuracy: 0.9300 - val_loss: 0.2343 - val_accuracy: 0.8750\n",
            "Epoch 38/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1494 - accuracy: 0.9274 - val_loss: 0.2403 - val_accuracy: 0.8750\n",
            "Epoch 39/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1445 - accuracy: 0.9252 - val_loss: 0.2258 - val_accuracy: 0.8813\n",
            "Epoch 40/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1238 - accuracy: 0.9389 - val_loss: 0.2071 - val_accuracy: 0.8875\n",
            "Epoch 41/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1264 - accuracy: 0.9370 - val_loss: 0.2383 - val_accuracy: 0.8875\n",
            "Epoch 42/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1388 - accuracy: 0.9535 - val_loss: 0.2080 - val_accuracy: 0.9000\n",
            "Epoch 43/200\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.1206 - accuracy: 0.9408 - val_loss: 0.2088 - val_accuracy: 0.8938\n",
            "Epoch 44/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1664 - accuracy: 0.9223 - val_loss: 0.2111 - val_accuracy: 0.9000\n",
            "Epoch 45/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1529 - accuracy: 0.9238 - val_loss: 0.2049 - val_accuracy: 0.9000\n",
            "Epoch 46/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1208 - accuracy: 0.9357 - val_loss: 0.2023 - val_accuracy: 0.9187\n",
            "Epoch 47/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1395 - accuracy: 0.9284 - val_loss: 0.1927 - val_accuracy: 0.9187\n",
            "Epoch 48/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1293 - accuracy: 0.9370 - val_loss: 0.2053 - val_accuracy: 0.9062\n",
            "Epoch 49/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1224 - accuracy: 0.9400 - val_loss: 0.2138 - val_accuracy: 0.9000\n",
            "Epoch 50/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1232 - accuracy: 0.9414 - val_loss: 0.2005 - val_accuracy: 0.9000\n",
            "Epoch 51/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1171 - accuracy: 0.9556 - val_loss: 0.2180 - val_accuracy: 0.9062\n",
            "Epoch 52/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1206 - accuracy: 0.9507 - val_loss: 0.2138 - val_accuracy: 0.9062\n",
            "Epoch 53/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1242 - accuracy: 0.9361 - val_loss: 0.2404 - val_accuracy: 0.8875\n",
            "Epoch 54/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1312 - accuracy: 0.9372 - val_loss: 0.2216 - val_accuracy: 0.8938\n",
            "Epoch 55/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1129 - accuracy: 0.9579 - val_loss: 0.2204 - val_accuracy: 0.9125\n",
            "Epoch 56/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1403 - accuracy: 0.9325 - val_loss: 0.1945 - val_accuracy: 0.9250\n",
            "Epoch 57/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1260 - accuracy: 0.9422 - val_loss: 0.2095 - val_accuracy: 0.8938\n",
            "Epoch 58/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0978 - accuracy: 0.9588 - val_loss: 0.2051 - val_accuracy: 0.9000\n",
            "Epoch 59/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1381 - accuracy: 0.9374 - val_loss: 0.2288 - val_accuracy: 0.9000\n",
            "Epoch 60/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1169 - accuracy: 0.9450 - val_loss: 0.2234 - val_accuracy: 0.8938\n",
            "Epoch 61/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1021 - accuracy: 0.9565 - val_loss: 0.2263 - val_accuracy: 0.9000\n",
            "Epoch 62/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.1054 - accuracy: 0.9456 - val_loss: 0.2228 - val_accuracy: 0.9125\n",
            "Epoch 63/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0834 - accuracy: 0.9748 - val_loss: 0.2373 - val_accuracy: 0.8938\n",
            "Epoch 64/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0923 - accuracy: 0.9582 - val_loss: 0.2335 - val_accuracy: 0.9062\n",
            "Epoch 65/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1032 - accuracy: 0.9538 - val_loss: 0.2541 - val_accuracy: 0.9187\n",
            "Epoch 66/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1004 - accuracy: 0.9501 - val_loss: 0.2256 - val_accuracy: 0.9187\n",
            "Epoch 67/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0706 - accuracy: 0.9729 - val_loss: 0.2256 - val_accuracy: 0.9250\n",
            "Epoch 68/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0889 - accuracy: 0.9649 - val_loss: 0.2428 - val_accuracy: 0.9125\n",
            "Epoch 69/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0865 - accuracy: 0.9626 - val_loss: 0.2528 - val_accuracy: 0.9125\n",
            "Epoch 70/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0937 - accuracy: 0.9635 - val_loss: 0.2595 - val_accuracy: 0.9000\n",
            "Epoch 71/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0980 - accuracy: 0.9530 - val_loss: 0.2388 - val_accuracy: 0.9000\n",
            "Epoch 72/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0998 - accuracy: 0.9655 - val_loss: 0.2612 - val_accuracy: 0.8938\n",
            "Epoch 73/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0968 - accuracy: 0.9541 - val_loss: 0.2706 - val_accuracy: 0.8875\n",
            "Epoch 74/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0879 - accuracy: 0.9605 - val_loss: 0.2674 - val_accuracy: 0.9000\n",
            "Epoch 75/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0803 - accuracy: 0.9667 - val_loss: 0.2654 - val_accuracy: 0.9000\n",
            "Epoch 76/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0870 - accuracy: 0.9620 - val_loss: 0.3081 - val_accuracy: 0.8875\n",
            "Epoch 77/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0626 - accuracy: 0.9726 - val_loss: 0.2610 - val_accuracy: 0.9187\n",
            "Epoch 78/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0838 - accuracy: 0.9567 - val_loss: 0.2839 - val_accuracy: 0.9125\n",
            "Epoch 79/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.1273 - accuracy: 0.9461 - val_loss: 0.2683 - val_accuracy: 0.9187\n",
            "Epoch 80/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0827 - accuracy: 0.9578 - val_loss: 0.2615 - val_accuracy: 0.9062\n",
            "Epoch 81/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0753 - accuracy: 0.9650 - val_loss: 0.2679 - val_accuracy: 0.9125\n",
            "Epoch 82/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0904 - accuracy: 0.9640 - val_loss: 0.2618 - val_accuracy: 0.9000\n",
            "Epoch 83/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0727 - accuracy: 0.9609 - val_loss: 0.2785 - val_accuracy: 0.9000\n",
            "Epoch 84/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0850 - accuracy: 0.9594 - val_loss: 0.2620 - val_accuracy: 0.9062\n",
            "Epoch 85/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0907 - accuracy: 0.9681 - val_loss: 0.2630 - val_accuracy: 0.9125\n",
            "Epoch 86/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0819 - accuracy: 0.9674 - val_loss: 0.2592 - val_accuracy: 0.9062\n",
            "Epoch 87/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0861 - accuracy: 0.9612 - val_loss: 0.2783 - val_accuracy: 0.8938\n",
            "Epoch 88/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0759 - accuracy: 0.9660 - val_loss: 0.3046 - val_accuracy: 0.9062\n",
            "Epoch 89/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0900 - accuracy: 0.9585 - val_loss: 0.3146 - val_accuracy: 0.8938\n",
            "Epoch 90/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0803 - accuracy: 0.9590 - val_loss: 0.3596 - val_accuracy: 0.9000\n",
            "Epoch 91/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0723 - accuracy: 0.9648 - val_loss: 0.3174 - val_accuracy: 0.8938\n",
            "Epoch 92/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0787 - accuracy: 0.9637 - val_loss: 0.3293 - val_accuracy: 0.9000\n",
            "Epoch 93/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0842 - accuracy: 0.9683 - val_loss: 0.3229 - val_accuracy: 0.9000\n",
            "Epoch 94/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0671 - accuracy: 0.9767 - val_loss: 0.2937 - val_accuracy: 0.9062\n",
            "Epoch 95/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0636 - accuracy: 0.9706 - val_loss: 0.2903 - val_accuracy: 0.8938\n",
            "Epoch 96/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0542 - accuracy: 0.9804 - val_loss: 0.2908 - val_accuracy: 0.9000\n",
            "Epoch 97/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0561 - accuracy: 0.9760 - val_loss: 0.3159 - val_accuracy: 0.9062\n",
            "Epoch 98/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0547 - accuracy: 0.9814 - val_loss: 0.3204 - val_accuracy: 0.9062\n",
            "Epoch 99/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0655 - accuracy: 0.9727 - val_loss: 0.3728 - val_accuracy: 0.9000\n",
            "Epoch 100/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0908 - accuracy: 0.9520 - val_loss: 0.3399 - val_accuracy: 0.8938\n",
            "Epoch 101/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0741 - accuracy: 0.9719 - val_loss: 0.3170 - val_accuracy: 0.9000\n",
            "Epoch 102/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0701 - accuracy: 0.9636 - val_loss: 0.2912 - val_accuracy: 0.8938\n",
            "Epoch 103/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0863 - accuracy: 0.9647 - val_loss: 0.3146 - val_accuracy: 0.9187\n",
            "Epoch 104/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0513 - accuracy: 0.9798 - val_loss: 0.3205 - val_accuracy: 0.8938\n",
            "Epoch 105/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0658 - accuracy: 0.9827 - val_loss: 0.3075 - val_accuracy: 0.9062\n",
            "Epoch 106/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0705 - accuracy: 0.9764 - val_loss: 0.3392 - val_accuracy: 0.9000\n",
            "Epoch 107/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0753 - accuracy: 0.9724 - val_loss: 0.3140 - val_accuracy: 0.9125\n",
            "Epoch 108/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0718 - accuracy: 0.9713 - val_loss: 0.3426 - val_accuracy: 0.8938\n",
            "Epoch 109/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0626 - accuracy: 0.9731 - val_loss: 0.3257 - val_accuracy: 0.8938\n",
            "Epoch 110/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0901 - accuracy: 0.9649 - val_loss: 0.3200 - val_accuracy: 0.8875\n",
            "Epoch 111/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0736 - accuracy: 0.9632 - val_loss: 0.3350 - val_accuracy: 0.8813\n",
            "Epoch 112/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0543 - accuracy: 0.9792 - val_loss: 0.3205 - val_accuracy: 0.9000\n",
            "Epoch 113/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0570 - accuracy: 0.9801 - val_loss: 0.3239 - val_accuracy: 0.8938\n",
            "Epoch 114/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0863 - accuracy: 0.9551 - val_loss: 0.3713 - val_accuracy: 0.9000\n",
            "Epoch 115/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0602 - accuracy: 0.9720 - val_loss: 0.3734 - val_accuracy: 0.9000\n",
            "Epoch 116/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0626 - accuracy: 0.9718 - val_loss: 0.3358 - val_accuracy: 0.9000\n",
            "Epoch 117/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0777 - accuracy: 0.9691 - val_loss: 0.3441 - val_accuracy: 0.9125\n",
            "Epoch 118/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0725 - accuracy: 0.9657 - val_loss: 0.4009 - val_accuracy: 0.8938\n",
            "Epoch 119/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0860 - accuracy: 0.9584 - val_loss: 0.3639 - val_accuracy: 0.9000\n",
            "Epoch 120/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0494 - accuracy: 0.9769 - val_loss: 0.3857 - val_accuracy: 0.8938\n",
            "Epoch 121/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0497 - accuracy: 0.9733 - val_loss: 0.3817 - val_accuracy: 0.8875\n",
            "Epoch 122/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0476 - accuracy: 0.9772 - val_loss: 0.3599 - val_accuracy: 0.8875\n",
            "Epoch 123/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0461 - accuracy: 0.9786 - val_loss: 0.4064 - val_accuracy: 0.8938\n",
            "Epoch 124/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0544 - accuracy: 0.9677 - val_loss: 0.3763 - val_accuracy: 0.8938\n",
            "Epoch 125/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0423 - accuracy: 0.9899 - val_loss: 0.3698 - val_accuracy: 0.8750\n",
            "Epoch 126/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0639 - accuracy: 0.9697 - val_loss: 0.3502 - val_accuracy: 0.8938\n",
            "Epoch 127/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0485 - accuracy: 0.9731 - val_loss: 0.3140 - val_accuracy: 0.8813\n",
            "Epoch 128/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0507 - accuracy: 0.9712 - val_loss: 0.3209 - val_accuracy: 0.9125\n",
            "Epoch 129/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0446 - accuracy: 0.9841 - val_loss: 0.3464 - val_accuracy: 0.9062\n",
            "Epoch 130/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0558 - accuracy: 0.9788 - val_loss: 0.3200 - val_accuracy: 0.9000\n",
            "Epoch 131/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0646 - accuracy: 0.9771 - val_loss: 0.3427 - val_accuracy: 0.9000\n",
            "Epoch 132/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0459 - accuracy: 0.9851 - val_loss: 0.3689 - val_accuracy: 0.8938\n",
            "Epoch 133/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0435 - accuracy: 0.9868 - val_loss: 0.3571 - val_accuracy: 0.8750\n",
            "Epoch 134/200\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0821 - accuracy: 0.9696 - val_loss: 0.3191 - val_accuracy: 0.8875\n",
            "Epoch 135/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0581 - accuracy: 0.9745 - val_loss: 0.3289 - val_accuracy: 0.8875\n",
            "Epoch 136/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0616 - accuracy: 0.9680 - val_loss: 0.3351 - val_accuracy: 0.8813\n",
            "Epoch 137/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0746 - accuracy: 0.9765 - val_loss: 0.3254 - val_accuracy: 0.8875\n",
            "Epoch 138/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0557 - accuracy: 0.9786 - val_loss: 0.3051 - val_accuracy: 0.8938\n",
            "Epoch 139/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0659 - accuracy: 0.9734 - val_loss: 0.2982 - val_accuracy: 0.9000\n",
            "Epoch 140/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0485 - accuracy: 0.9802 - val_loss: 0.3069 - val_accuracy: 0.9000\n",
            "Epoch 141/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0524 - accuracy: 0.9794 - val_loss: 0.2855 - val_accuracy: 0.8938\n",
            "Epoch 142/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0441 - accuracy: 0.9886 - val_loss: 0.2951 - val_accuracy: 0.8750\n",
            "Epoch 143/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0687 - accuracy: 0.9699 - val_loss: 0.3148 - val_accuracy: 0.8875\n",
            "Epoch 144/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0414 - accuracy: 0.9856 - val_loss: 0.3126 - val_accuracy: 0.9062\n",
            "Epoch 145/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0507 - accuracy: 0.9844 - val_loss: 0.3125 - val_accuracy: 0.8875\n",
            "Epoch 146/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0517 - accuracy: 0.9801 - val_loss: 0.3281 - val_accuracy: 0.8875\n",
            "Epoch 147/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0381 - accuracy: 0.9863 - val_loss: 0.3438 - val_accuracy: 0.8687\n",
            "Epoch 148/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0401 - accuracy: 0.9794 - val_loss: 0.3215 - val_accuracy: 0.8875\n",
            "Epoch 149/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0340 - accuracy: 0.9770 - val_loss: 0.3280 - val_accuracy: 0.8750\n",
            "Epoch 150/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0431 - accuracy: 0.9794 - val_loss: 0.3442 - val_accuracy: 0.8687\n",
            "Epoch 151/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0331 - accuracy: 0.9859 - val_loss: 0.3385 - val_accuracy: 0.8750\n",
            "Epoch 152/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0393 - accuracy: 0.9796 - val_loss: 0.3212 - val_accuracy: 0.8750\n",
            "Epoch 153/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0409 - accuracy: 0.9869 - val_loss: 0.3438 - val_accuracy: 0.9000\n",
            "Epoch 154/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0299 - accuracy: 0.9885 - val_loss: 0.3492 - val_accuracy: 0.8938\n",
            "Epoch 155/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0351 - accuracy: 0.9886 - val_loss: 0.3616 - val_accuracy: 0.8938\n",
            "Epoch 156/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0368 - accuracy: 0.9849 - val_loss: 0.3480 - val_accuracy: 0.8813\n",
            "Epoch 157/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0656 - accuracy: 0.9775 - val_loss: 0.4058 - val_accuracy: 0.9000\n",
            "Epoch 158/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0406 - accuracy: 0.9851 - val_loss: 0.3760 - val_accuracy: 0.8938\n",
            "Epoch 159/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0247 - accuracy: 0.9904 - val_loss: 0.3839 - val_accuracy: 0.8875\n",
            "Epoch 160/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0392 - accuracy: 0.9843 - val_loss: 0.3856 - val_accuracy: 0.8875\n",
            "Epoch 161/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0436 - accuracy: 0.9886 - val_loss: 0.3557 - val_accuracy: 0.8938\n",
            "Epoch 162/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0457 - accuracy: 0.9742 - val_loss: 0.3373 - val_accuracy: 0.8938\n",
            "Epoch 163/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0488 - accuracy: 0.9808 - val_loss: 0.3334 - val_accuracy: 0.8813\n",
            "Epoch 164/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0534 - accuracy: 0.9782 - val_loss: 0.3481 - val_accuracy: 0.8875\n",
            "Epoch 165/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0710 - accuracy: 0.9806 - val_loss: 0.3585 - val_accuracy: 0.8687\n",
            "Epoch 166/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0323 - accuracy: 0.9850 - val_loss: 0.3432 - val_accuracy: 0.8813\n",
            "Epoch 167/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0618 - accuracy: 0.9840 - val_loss: 0.3621 - val_accuracy: 0.8875\n",
            "Epoch 168/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0428 - accuracy: 0.9853 - val_loss: 0.3635 - val_accuracy: 0.8875\n",
            "Epoch 169/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0482 - accuracy: 0.9842 - val_loss: 0.3934 - val_accuracy: 0.8813\n",
            "Epoch 170/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0325 - accuracy: 0.9897 - val_loss: 0.3797 - val_accuracy: 0.8813\n",
            "Epoch 171/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0492 - accuracy: 0.9768 - val_loss: 0.3527 - val_accuracy: 0.8938\n",
            "Epoch 172/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0315 - accuracy: 0.9885 - val_loss: 0.3710 - val_accuracy: 0.9000\n",
            "Epoch 173/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0349 - accuracy: 0.9837 - val_loss: 0.4015 - val_accuracy: 0.8875\n",
            "Epoch 174/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0422 - accuracy: 0.9806 - val_loss: 0.3786 - val_accuracy: 0.8875\n",
            "Epoch 175/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0459 - accuracy: 0.9778 - val_loss: 0.3865 - val_accuracy: 0.8750\n",
            "Epoch 176/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0223 - accuracy: 0.9916 - val_loss: 0.4011 - val_accuracy: 0.8875\n",
            "Epoch 177/200\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.0240 - accuracy: 0.9882 - val_loss: 0.4228 - val_accuracy: 0.8813\n",
            "Epoch 178/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0478 - accuracy: 0.9851 - val_loss: 0.4106 - val_accuracy: 0.8938\n",
            "Epoch 179/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0365 - accuracy: 0.9838 - val_loss: 0.4269 - val_accuracy: 0.8938\n",
            "Epoch 180/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0365 - accuracy: 0.9835 - val_loss: 0.4339 - val_accuracy: 0.8875\n",
            "Epoch 181/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0314 - accuracy: 0.9888 - val_loss: 0.4421 - val_accuracy: 0.8938\n",
            "Epoch 182/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0287 - accuracy: 0.9836 - val_loss: 0.4609 - val_accuracy: 0.8813\n",
            "Epoch 183/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.4618 - val_accuracy: 0.8875\n",
            "Epoch 184/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0407 - accuracy: 0.9834 - val_loss: 0.4711 - val_accuracy: 0.8938\n",
            "Epoch 185/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0349 - accuracy: 0.9846 - val_loss: 0.4181 - val_accuracy: 0.8875\n",
            "Epoch 186/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0418 - accuracy: 0.9863 - val_loss: 0.4126 - val_accuracy: 0.8813\n",
            "Epoch 187/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0344 - accuracy: 0.9792 - val_loss: 0.4316 - val_accuracy: 0.8813\n",
            "Epoch 188/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0461 - accuracy: 0.9835 - val_loss: 0.4224 - val_accuracy: 0.8875\n",
            "Epoch 189/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0358 - accuracy: 0.9875 - val_loss: 0.4495 - val_accuracy: 0.8813\n",
            "Epoch 190/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0403 - accuracy: 0.9797 - val_loss: 0.4889 - val_accuracy: 0.8813\n",
            "Epoch 191/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0266 - accuracy: 0.9901 - val_loss: 0.4692 - val_accuracy: 0.8813\n",
            "Epoch 192/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0485 - accuracy: 0.9825 - val_loss: 0.4559 - val_accuracy: 0.8687\n",
            "Epoch 193/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0390 - accuracy: 0.9796 - val_loss: 0.3622 - val_accuracy: 0.9000\n",
            "Epoch 194/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0434 - accuracy: 0.9855 - val_loss: 0.4109 - val_accuracy: 0.9062\n",
            "Epoch 195/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0241 - accuracy: 0.9955 - val_loss: 0.4269 - val_accuracy: 0.8875\n",
            "Epoch 196/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0265 - accuracy: 0.9936 - val_loss: 0.4416 - val_accuracy: 0.8813\n",
            "Epoch 197/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0198 - accuracy: 0.9923 - val_loss: 0.4351 - val_accuracy: 0.8938\n",
            "Epoch 198/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0221 - accuracy: 0.9894 - val_loss: 0.4577 - val_accuracy: 0.8813\n",
            "Epoch 199/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0395 - accuracy: 0.9870 - val_loss: 0.4458 - val_accuracy: 0.8813\n",
            "Epoch 200/200\n",
            "61/61 [==============================] - 1s 9ms/step - loss: 0.0257 - accuracy: 0.9881 - val_loss: 0.4343 - val_accuracy: 0.8938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzLHiYbNfVfX",
        "outputId": "9386cd68-ea6d-4da6-8c36-3939b43bb151"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(Ntest_seq, Ntest_lab, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 - 0s - loss: 0.7859 - accuracy: 0.8610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bifAL9U3MEy-"
      },
      "source": [
        "pred_pro=model.predict(Ntest_seq) #计算概率"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7alJ6DxkvFE",
        "outputId": "90069541-c994-4c32-a05d-8a3ceeb326ed"
      },
      "source": [
        "pred_pro.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(482, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hpvqy8Jky6CJ",
        "outputId": "5beaecbb-8b9b-4d01-c128-a2ed05a78e9e"
      },
      "source": [
        "# PR曲线（精确率/召回率）\n",
        "from sklearn.metrics import precision_recall_curve,auc\n",
        "precision, recall, thresholds=precision_recall_curve(Ntest_lab,pred_pro[:,1]) # 计算多种阈值的p,r\n",
        "pr_auc = auc(recall, precision)\n",
        "print(pr_auc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9243837719890594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYtx3EXaVCRt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "8d84d4fb-313a-4a4b-dd5d-84a856c12f3a"
      },
      "source": [
        "# PR曲线\n",
        "def plot_pr_curve(recall,precision,label=None):\n",
        "    plt.plot(recall,precision,'b--',linewidth=2,label=label)\n",
        "    plt.axis([0,1,0,1])\n",
        "    plt.xlabel('recall')\n",
        "    plt.ylabel('precision')\n",
        "plot_pr_curve(recall,precision)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivTDOtksF3Op"
      },
      "source": [
        "listnew=[list(recall),list(precision)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pOgte10pWu4"
      },
      "source": [
        "#def savedata2D(list1,filepath,test_acc,AUC):\n",
        "def savedata2D(list1,filepath):\n",
        "    output = open(filepath,'w+',encoding='utf-8')\n",
        "    for i in range(len(list1)):\n",
        "        for j in range(len(list1[i])):\n",
        "                output.write(str(list1[i][j]))    \n",
        "                output.write('\\t')   \n",
        "        output.write('\\n')\n",
        "    #output.write(AUC)\n",
        "    #output.write('\\n')\n",
        "    #output.write(str(test_acc))\n",
        "    #output.write('\\n')\n",
        "    output.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X62fwiTJtban"
      },
      "source": [
        "if after==True:\n",
        "  fp_pr='/content/data_PR_off_after.txt'\n",
        "else:\n",
        "  fp_pr='/content/data_PR_off_before.txt'\n",
        "savedata2D(listnew,fp_pr)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}